{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia 深度學習：卷積神經網路模型簡介\n",
    "\n",
    "## 作業 033：訓練 CNN 學習門牌號碼資料集\n",
    "\n",
    "訓練一個 CNN 模型來學習門牌號碼資料集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: @epochs, onecold, onehotbatch, throttle, logitcrossentropy\n",
    "using MLDatasets\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Float32[0.14901961 0.15294118 … 0.19607843 0.1882353; 0.15294118 0.15294118 … 0.2 0.1882353; … ; 0.16470589 0.16862746 … 0.1764706 0.17254902; 0.15294118 0.15294118 … 0.16470589 0.16470589]\n",
       "\n",
       "Float32[0.40392157 0.40784314 … 0.45882353 0.4509804; 0.40784314 0.40784314 … 0.4627451 0.4509804; … ; 0.40392157 0.39607844 … 0.45490196 0.4509804; 0.38039216 0.38039216 … 0.44313726 0.44313726]\n",
       "\n",
       "Float32[0.23529412 0.23921569 … 0.29803923 0.2901961; 0.23921569 0.23921569 … 0.3019608 0.2901961; … ; 0.24313726 0.24705882 … 0.28235295 0.2784314; 0.22352941 0.22352941 … 0.27058825 0.2784314]\n",
       "\n",
       "Float32[0.5058824 0.5254902 … 0.5411765 0.5137255; 0.49803922 0.52156866 … 0.50980395 0.47843137; … ; 0.48235294 0.49411765 … 0.39607844 0.43529412; 0.48235294 0.49019608 … 0.4392157 0.48235294]\n",
       "\n",
       "Float32[0.5568628 0.5882353 … 0.59607846 0.5686275; 0.56078434 0.58431375 … 0.5647059 0.53333336; … ; 0.5254902 0.5372549 … 0.41960785 0.4627451; 0.5294118 0.5372549 … 0.4627451 0.50980395]\n",
       "\n",
       "Float32[0.6 0.627451 … 0.64705884 0.61960787; 0.59607846 0.61960787 … 0.6156863 0.58431375; … ; 0.6117647 0.6156863 … 0.5254902 0.5647059; 0.6156863 0.61960787 … 0.5647059 0.6117647]\n",
       "\n",
       "Float32[0.5882353 0.5882353 … 0.5764706 0.62352943; 0.5882353 0.5921569 … 0.5764706 0.62352943; … ; 0.5882353 0.6 … 0.54509807 0.59607846; 0.5764706 0.5882353 … 0.5411765 0.59607846]\n",
       "\n",
       "Float32[0.627451 0.627451 … 0.64705884 0.69411767; 0.6392157 0.6392157 … 0.6431373 0.69411767; … ; 0.67058825 0.67058825 … 0.60784316 0.65882355; 0.6627451 0.6627451 … 0.60784316 0.65882355]\n",
       "\n",
       "Float32[0.6627451 0.6627451 … 0.7019608 0.7411765; 0.6666667 0.6627451 … 0.7019608 0.74509805; … ; 0.70980394 0.7058824 … 0.6666667 0.7137255; 0.7058824 0.7019608 … 0.67058825 0.7176471]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.050980393 0.050980393 … 0.043137256 0.047058824; 0.047058824 0.047058824 … 0.047058824 0.050980393; … ; 0.10980392 0.11764706 … 0.13725491 0.13725491; 0.105882354 0.11372549 … 0.14509805 0.15294118]\n",
       "\n",
       "Float32[0.05882353 0.05490196 … 0.047058824 0.050980393; 0.050980393 0.050980393 … 0.050980393 0.05490196; … ; 0.1254902 0.13725491 … 0.14117648 0.14117648; 0.12941177 0.13725491 … 0.14901961 0.15294118]\n",
       "\n",
       "Float32[0.05490196 0.05882353 … 0.05490196 0.05882353; 0.05882353 0.05882353 … 0.05882353 0.0627451; … ; 0.12941177 0.13333334 … 0.16470589 0.16862746; 0.12156863 0.12941177 … 0.1764706 0.18431373]\n",
       "\n",
       "Float32[0.23529412 0.23529412 … 0.2627451 0.25882354; 0.23921569 0.23921569 … 0.2627451 0.25490198; … ; 0.4745098 0.49411765 … 0.43529412 0.41960785; 0.4745098 0.49803922 … 0.4392157 0.41568628]\n",
       "\n",
       "Float32[0.21960784 0.22352941 … 0.21960784 0.20784314; 0.22745098 0.23529412 … 0.22352941 0.20784314; … ; 0.5019608 0.52156866 … 0.4392157 0.40784314; 0.5019608 0.5254902 … 0.44313726 0.40392157]\n",
       "\n",
       "Float32[0.2784314 0.29411766 … 0.26666668 0.24705882; 0.2901961 0.30588236 … 0.27058825 0.24705882; … ; 0.5411765 0.56078434 … 0.4862745 0.45882353; 0.5411765 0.5647059 … 0.49019608 0.45490196]\n",
       "\n",
       "Float32[0.40392157 0.43529412 … 0.47058824 0.43529412; 0.40392157 0.43137255 … 0.46666667 0.43529412; … ; 0.41568628 0.4509804 … 0.37254903 0.32156864; 0.4 0.44313726 … 0.36862746 0.32156864]\n",
       "\n",
       "Float32[0.45490196 0.49411765 … 0.4509804 0.40784314; 0.45882353 0.49411765 … 0.4509804 0.4117647; … ; 0.41960785 0.4627451 … 0.35686275 0.3019608; 0.40392157 0.44705883 … 0.3529412 0.29803923]\n",
       "\n",
       "Float32[0.5058824 0.54509807 … 0.52156866 0.47843137; 0.50980395 0.54509807 … 0.5176471 0.47843137; … ; 0.4 0.4392157 … 0.3529412 0.29411766; 0.38039216 0.41960785 … 0.3372549 0.2901961], [5, 2, 1, 10, 6, 1, 9, 1, 1, 8  …  4, 6, 5, 7, 1, 8, 4, 8, 1, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, train_y = SVHN2.traindata(Float32, 1:20000)\n",
    "test_X,  test_y  = SVHN2.testdata(Float32, 1:2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×2000 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n",
       " ⋅  ⋅  1  ⋅  ⋅  1  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  1  ⋅\n",
       " ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅\n",
       " 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1     ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  …  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     1  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅     ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  1  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = onehotbatch(train_y, 1:10)\n",
    "test_y = onehotbatch(test_y, 1:10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader{Tuple{Array{Float32, 4}, Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}}}, Random._GLOBAL_RNG}((Float32[0.14901961 0.15294118 … 0.19607843 0.1882353; 0.15294118 0.15294118 … 0.2 0.1882353; … ; 0.16470589 0.16862746 … 0.1764706 0.17254902; 0.15294118 0.15294118 … 0.16470589 0.16470589]\n",
       "\n",
       "Float32[0.40392157 0.40784314 … 0.45882353 0.4509804; 0.40784314 0.40784314 … 0.4627451 0.4509804; … ; 0.40392157 0.39607844 … 0.45490196 0.4509804; 0.38039216 0.38039216 … 0.44313726 0.44313726]\n",
       "\n",
       "Float32[0.23529412 0.23921569 … 0.29803923 0.2901961; 0.23921569 0.23921569 … 0.3019608 0.2901961; … ; 0.24313726 0.24705882 … 0.28235295 0.2784314; 0.22352941 0.22352941 … 0.27058825 0.2784314]\n",
       "\n",
       "Float32[0.5058824 0.5254902 … 0.5411765 0.5137255; 0.49803922 0.52156866 … 0.50980395 0.47843137; … ; 0.48235294 0.49411765 … 0.39607844 0.43529412; 0.48235294 0.49019608 … 0.4392157 0.48235294]\n",
       "\n",
       "Float32[0.5568628 0.5882353 … 0.59607846 0.5686275; 0.56078434 0.58431375 … 0.5647059 0.53333336; … ; 0.5254902 0.5372549 … 0.41960785 0.4627451; 0.5294118 0.5372549 … 0.4627451 0.50980395]\n",
       "\n",
       "Float32[0.6 0.627451 … 0.64705884 0.61960787; 0.59607846 0.61960787 … 0.6156863 0.58431375; … ; 0.6117647 0.6156863 … 0.5254902 0.5647059; 0.6156863 0.61960787 … 0.5647059 0.6117647]\n",
       "\n",
       "Float32[0.5882353 0.5882353 … 0.5764706 0.62352943; 0.5882353 0.5921569 … 0.5764706 0.62352943; … ; 0.5882353 0.6 … 0.54509807 0.59607846; 0.5764706 0.5882353 … 0.5411765 0.59607846]\n",
       "\n",
       "Float32[0.627451 0.627451 … 0.64705884 0.69411767; 0.6392157 0.6392157 … 0.6431373 0.69411767; … ; 0.67058825 0.67058825 … 0.60784316 0.65882355; 0.6627451 0.6627451 … 0.60784316 0.65882355]\n",
       "\n",
       "Float32[0.6627451 0.6627451 … 0.7019608 0.7411765; 0.6666667 0.6627451 … 0.7019608 0.74509805; … ; 0.70980394 0.7058824 … 0.6666667 0.7137255; 0.7058824 0.7019608 … 0.67058825 0.7176471]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.050980393 0.050980393 … 0.043137256 0.047058824; 0.047058824 0.047058824 … 0.047058824 0.050980393; … ; 0.10980392 0.11764706 … 0.13725491 0.13725491; 0.105882354 0.11372549 … 0.14509805 0.15294118]\n",
       "\n",
       "Float32[0.05882353 0.05490196 … 0.047058824 0.050980393; 0.050980393 0.050980393 … 0.050980393 0.05490196; … ; 0.1254902 0.13725491 … 0.14117648 0.14117648; 0.12941177 0.13725491 … 0.14901961 0.15294118]\n",
       "\n",
       "Float32[0.05490196 0.05882353 … 0.05490196 0.05882353; 0.05882353 0.05882353 … 0.05882353 0.0627451; … ; 0.12941177 0.13333334 … 0.16470589 0.16862746; 0.12156863 0.12941177 … 0.1764706 0.18431373]\n",
       "\n",
       "Float32[0.23529412 0.23529412 … 0.2627451 0.25882354; 0.23921569 0.23921569 … 0.2627451 0.25490198; … ; 0.4745098 0.49411765 … 0.43529412 0.41960785; 0.4745098 0.49803922 … 0.4392157 0.41568628]\n",
       "\n",
       "Float32[0.21960784 0.22352941 … 0.21960784 0.20784314; 0.22745098 0.23529412 … 0.22352941 0.20784314; … ; 0.5019608 0.52156866 … 0.4392157 0.40784314; 0.5019608 0.5254902 … 0.44313726 0.40392157]\n",
       "\n",
       "Float32[0.2784314 0.29411766 … 0.26666668 0.24705882; 0.2901961 0.30588236 … 0.27058825 0.24705882; … ; 0.5411765 0.56078434 … 0.4862745 0.45882353; 0.5411765 0.5647059 … 0.49019608 0.45490196]\n",
       "\n",
       "Float32[0.40392157 0.43529412 … 0.47058824 0.43529412; 0.40392157 0.43137255 … 0.46666667 0.43529412; … ; 0.41568628 0.4509804 … 0.37254903 0.32156864; 0.4 0.44313726 … 0.36862746 0.32156864]\n",
       "\n",
       "Float32[0.45490196 0.49411765 … 0.4509804 0.40784314; 0.45882353 0.49411765 … 0.4509804 0.4117647; … ; 0.41960785 0.4627451 … 0.35686275 0.3019608; 0.40392157 0.44705883 … 0.3529412 0.29803923]\n",
       "\n",
       "Float32[0.5058824 0.54509807 … 0.52156866 0.47843137; 0.50980395 0.54509807 … 0.5176471 0.47843137; … ; 0.4 0.4392157 … 0.3529412 0.29411766; 0.38039216 0.41960785 … 0.3372549 0.2901961], Bool[0 0 … 1 0; 0 1 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]), 1024, 2000, true, 2000, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000], false, Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = 1024\n",
    "train = DataLoader((train_X, train_y), batchsize=batchsize, shuffle=true)\n",
    "test = DataLoader((test_X, test_y), batchsize=batchsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 3 => 16, relu, pad=1),   \u001b[90m# 448 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Conv((3, 3), 16 => 32, relu, pad=1),  \u001b[90m# 4_640 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Conv((3, 3), 32 => 32, relu, pad=1),  \u001b[90m# 9_248 parameters\u001b[39m\n",
       "  MaxPool((2, 2)),\n",
       "  Flux.flatten,\n",
       "  Dense(512, 10),                       \u001b[90m# 5_130 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ")\u001b[90m                   # Total: 8 arrays, \u001b[39m19_466 parameters, 77.453 KiB."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 3=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    flatten,\n",
    "    Dense(512, 10),\n",
    "    softmax)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×2000 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n",
       " ⋅  ⋅  1  ⋅  ⋅  1  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  1  ⋅\n",
       " ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅\n",
       " 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1     ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  …  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     1  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅     ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  1  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model |> gpu\n",
    "train_X = train_X |> gpu\n",
    "train_y = train_y |> gpu\n",
    "test_X = test_X |> gpu\n",
    "test_y = test_y |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataLoader{Tuple{Array{Float32, 4}, Flux.OneHotArray{UInt32, 10, 1, 2, Vector{UInt32}}}, Random._GLOBAL_RNG}((Float32[0.14901961 0.15294118 … 0.19607843 0.1882353; 0.15294118 0.15294118 … 0.2 0.1882353; … ; 0.16470589 0.16862746 … 0.1764706 0.17254902; 0.15294118 0.15294118 … 0.16470589 0.16470589]\n",
       "\n",
       "Float32[0.40392157 0.40784314 … 0.45882353 0.4509804; 0.40784314 0.40784314 … 0.4627451 0.4509804; … ; 0.40392157 0.39607844 … 0.45490196 0.4509804; 0.38039216 0.38039216 … 0.44313726 0.44313726]\n",
       "\n",
       "Float32[0.23529412 0.23921569 … 0.29803923 0.2901961; 0.23921569 0.23921569 … 0.3019608 0.2901961; … ; 0.24313726 0.24705882 … 0.28235295 0.2784314; 0.22352941 0.22352941 … 0.27058825 0.2784314]\n",
       "\n",
       "Float32[0.5058824 0.5254902 … 0.5411765 0.5137255; 0.49803922 0.52156866 … 0.50980395 0.47843137; … ; 0.48235294 0.49411765 … 0.39607844 0.43529412; 0.48235294 0.49019608 … 0.4392157 0.48235294]\n",
       "\n",
       "Float32[0.5568628 0.5882353 … 0.59607846 0.5686275; 0.56078434 0.58431375 … 0.5647059 0.53333336; … ; 0.5254902 0.5372549 … 0.41960785 0.4627451; 0.5294118 0.5372549 … 0.4627451 0.50980395]\n",
       "\n",
       "Float32[0.6 0.627451 … 0.64705884 0.61960787; 0.59607846 0.61960787 … 0.6156863 0.58431375; … ; 0.6117647 0.6156863 … 0.5254902 0.5647059; 0.6156863 0.61960787 … 0.5647059 0.6117647]\n",
       "\n",
       "Float32[0.5882353 0.5882353 … 0.5764706 0.62352943; 0.5882353 0.5921569 … 0.5764706 0.62352943; … ; 0.5882353 0.6 … 0.54509807 0.59607846; 0.5764706 0.5882353 … 0.5411765 0.59607846]\n",
       "\n",
       "Float32[0.627451 0.627451 … 0.64705884 0.69411767; 0.6392157 0.6392157 … 0.6431373 0.69411767; … ; 0.67058825 0.67058825 … 0.60784316 0.65882355; 0.6627451 0.6627451 … 0.60784316 0.65882355]\n",
       "\n",
       "Float32[0.6627451 0.6627451 … 0.7019608 0.7411765; 0.6666667 0.6627451 … 0.7019608 0.74509805; … ; 0.70980394 0.7058824 … 0.6666667 0.7137255; 0.7058824 0.7019608 … 0.67058825 0.7176471]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.050980393 0.050980393 … 0.043137256 0.047058824; 0.047058824 0.047058824 … 0.047058824 0.050980393; … ; 0.10980392 0.11764706 … 0.13725491 0.13725491; 0.105882354 0.11372549 … 0.14509805 0.15294118]\n",
       "\n",
       "Float32[0.05882353 0.05490196 … 0.047058824 0.050980393; 0.050980393 0.050980393 … 0.050980393 0.05490196; … ; 0.1254902 0.13725491 … 0.14117648 0.14117648; 0.12941177 0.13725491 … 0.14901961 0.15294118]\n",
       "\n",
       "Float32[0.05490196 0.05882353 … 0.05490196 0.05882353; 0.05882353 0.05882353 … 0.05882353 0.0627451; … ; 0.12941177 0.13333334 … 0.16470589 0.16862746; 0.12156863 0.12941177 … 0.1764706 0.18431373]\n",
       "\n",
       "Float32[0.23529412 0.23529412 … 0.2627451 0.25882354; 0.23921569 0.23921569 … 0.2627451 0.25490198; … ; 0.4745098 0.49411765 … 0.43529412 0.41960785; 0.4745098 0.49803922 … 0.4392157 0.41568628]\n",
       "\n",
       "Float32[0.21960784 0.22352941 … 0.21960784 0.20784314; 0.22745098 0.23529412 … 0.22352941 0.20784314; … ; 0.5019608 0.52156866 … 0.4392157 0.40784314; 0.5019608 0.5254902 … 0.44313726 0.40392157]\n",
       "\n",
       "Float32[0.2784314 0.29411766 … 0.26666668 0.24705882; 0.2901961 0.30588236 … 0.27058825 0.24705882; … ; 0.5411765 0.56078434 … 0.4862745 0.45882353; 0.5411765 0.5647059 … 0.49019608 0.45490196]\n",
       "\n",
       "Float32[0.40392157 0.43529412 … 0.47058824 0.43529412; 0.40392157 0.43137255 … 0.46666667 0.43529412; … ; 0.41568628 0.4509804 … 0.37254903 0.32156864; 0.4 0.44313726 … 0.36862746 0.32156864]\n",
       "\n",
       "Float32[0.45490196 0.49411765 … 0.4509804 0.40784314; 0.45882353 0.49411765 … 0.4509804 0.4117647; … ; 0.41960785 0.4627451 … 0.35686275 0.3019608; 0.40392157 0.44705883 … 0.3529412 0.29803923]\n",
       "\n",
       "Float32[0.5058824 0.54509807 … 0.52156866 0.47843137; 0.50980395 0.54509807 … 0.5176471 0.47843137; … ; 0.4 0.4392157 … 0.3529412 0.29411766; 0.38039216 0.41960785 … 0.3372549 0.2901961], Bool[0 0 … 1 0; 0 1 … 0 0; … ; 0 0 … 0 0; 0 0 … 0 0]), 64, 2000, true, 2000, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000], false, Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize=64\n",
    "train = DataLoader((train_X, train_y), batchsize=batchsize, shuffle=true)\n",
    "test = DataLoader((test_X, test_y), batchsize=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y) = logitcrossentropy(model(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_loss()\n",
    "    l = 0f0\n",
    "    for (x, y) in test\n",
    "        l += loss(x, y)\n",
    "    end\n",
    "    l/length(test)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalcb (generic function with 1 method)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalcb() = @show(test_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9630884f0\n",
      "test_loss() = 1.9655123f0\n",
      "test_loss() = 1.9626354f0\n",
      "test_loss() = 1.9589067f0\n",
      "test_loss() = 1.9587952f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.960035f0\n",
      "test_loss() = 1.9632282f0\n",
      "test_loss() = 1.9604708f0\n",
      "test_loss() = 1.9607778f0\n",
      "test_loss() = 1.9651887f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9601933f0\n",
      "test_loss() = 1.9610611f0\n",
      "test_loss() = 1.9594051f0\n",
      "test_loss() = 1.9580284f0\n",
      "test_loss() = 1.965058f0\n",
      "test_loss() = 1.9599782f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9587538f0\n",
      "test_loss() = 1.9583864f0\n",
      "test_loss() = 1.9555838f0\n",
      "test_loss() = 1.9621316f0\n",
      "test_loss() = 1.9648494f0\n",
      "test_loss() = 1.961512f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9608914f0\n",
      "test_loss() = 1.9631209f0\n",
      "test_loss() = 1.9641564f0\n",
      "test_loss() = 1.9593104f0\n",
      "test_loss() = 1.9626603f0\n",
      "test_loss() = 1.9599625f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9602798f0\n",
      "test_loss() = 1.9601407f0\n",
      "test_loss() = 1.955037f0\n",
      "test_loss() = 1.9555542f0\n",
      "test_loss() = 1.9636625f0\n",
      "test_loss() = 1.9570119f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9607804f0\n",
      "test_loss() = 1.948043f0\n",
      "test_loss() = 1.953749f0\n",
      "test_loss() = 1.953904f0\n",
      "test_loss() = 1.9468143f0\n",
      "test_loss() = 1.9478166f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9474492f0\n",
      "test_loss() = 1.9471439f0\n",
      "test_loss() = 1.941766f0\n",
      "test_loss() = 1.9494988f0\n",
      "test_loss() = 1.9294126f0\n",
      "test_loss() = 1.9303796f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9238663f0\n",
      "test_loss() = 1.9339122f0\n",
      "test_loss() = 1.9304205f0\n",
      "test_loss() = 1.9282204f0\n",
      "test_loss() = 1.9263082f0\n",
      "test_loss() = 1.9251726f0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main C:\\Users\\evanl\\.julia\\packages\\Flux\\Zz9RI\\src\\optimise\\train.jl:138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss() = 1.9354784f0\n",
      "test_loss() = 1.92593f0\n",
      "test_loss() = 1.9261026f0\n",
      "test_loss() = 1.9196757f0\n",
      "test_loss() = 1.9196215f0\n",
      "test_loss() = 1.9220351f0\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "@epochs epochs Flux.train!(loss, params(model), train, ADAM(0.002), cb=throttle(evalcb, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.539"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.90%\n"
     ]
    }
   ],
   "source": [
    "using Printf\n",
    "@printf(\"Accuracy: %.2f%%\\n\", accuracy(test_X, test_y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
